{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNYFLuVSEtKW",
        "outputId": "36cccea0-0383-43ee-b11f-121d698032e7"
      },
      "id": "FNYFLuVSEtKW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = \"\"\"\n",
        "Searle revised the speech acts classification and claimed that all speech acts fall into five categories: (1) Representative/Assertive: Speech act that expresses speaker‚Äôs belief and that commits the speaker to the truth of what is asserted (i.e., words fit the world. Example: üòÇ Statements); (2) Directive: Speech act that expresses speaker‚Äôs wish and making an attempt to get the hearer to do something (i.e., world fits the words. Example: Requests); (3) Commissive: Speech act that expresses speaker‚Äôs intention and marking the commitment for the speaker to engage in future action (I.e., world fits the words. Example: Promise); (4) Expressive: Speech act that expresses speaker‚Äôs psychological states which has no direction of fit between the world and words (Example: Apologies) and (5) Declaration: Speech act that brings change in (institutional) reality and has bilateral fit between world and words (Example: Baptizing). üòÇ\n",
        "üëç A number of studies have applied speech acts analysis in CMC environments. V√°squez (2011) studied complaints on the travel website TripAdvisor and concluded that complaints co-occurred more frequently with advice and recommendations and they were considered mostly indirect in nature. Other studies focused on users‚Äô self-representation in CMC environments. By examining away messages in Instant Messenger (IM), Nastri et al. (2006) found that they were constructed primarily with assertives, followed by expressives and commissives, but seldom with directives. The authors concluded that away messages tended to reflect both informational and entertainment goals. Similarly, Carr et al. (2012) investigated self-presentation in Facebook status messages and found that they were mostly constructed with expressives, followed by assertives. üòç Their findings demonstrated differences in how users expressed themselves in alternate media. Given that text-based speech acts often co-occur with emoticons and emojis in CMC, some studies have investigated the relationship between speech acts and emoticon usage in message construction. Dresner and Herring (2010) examined the pragmatic function of emoticons and argued that the primary function of emoticon was not to convey emotion but to indicate an illocutionary force, which is the intended effect of the utterance. While their study provided a more nuanced understanding of the functions of emoticons, their study was not situated in a particular CMC setting. In light of this, Skovholt et al. (2014) investigated the communicative functions of emoticons in workplace emails by adopting speech act theory and politeness theory. Through identification of speech acts followed by emoticons in workplace emails, they found that emoticons contributed to modifying the propositional content and the illocutionary force of speech acts, which corresponded with Drenser and Herring‚Äôs results (2010). üòç More recently, the popularity of emoji use have attracted scholars‚Äô interests. Ge-Stadnyk (2021) examined and compared how social media influencers on Weibo (a Chinese Microblogging site) and Twitter used emoji sequences when engaging in self-presentation. The study identified a variety of text-based speech acts, emoji functions, and functional relations by conducting speech act and pragmatic function analyses and claimed that emoji sequences functioning as ‚Äòemphasis on text‚Äô was most employed in connection with accompanying texts in both Weibo and Twitter data (p. 378). To our best knowledge, studies on speech acts with emoji usage in self-help online discussion forums is sparse. This study expands the current research scope by examining the text-based speech acts and the communicative functions of emoji in an online self-help discussion forum related to COVID-19, with the aim to investigate how Hong Kong forum users framed their COVID-19 experiences, expressed their emotions and seek socioemotional support from others amid a global health crisis. üòç\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Pry6xCNZEo8S"
      },
      "id": "Pry6xCNZEo8S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Text normalization**"
      ],
      "metadata": {
        "id": "qyNbx1_3KcWU"
      },
      "id": "qyNbx1_3KcWU"
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_text = text_data.lower()\n",
        "normalized_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "IOYhUOdcEerG",
        "outputId": "e1563d66-0ffe-4c74-ff37-ded4b300acb4"
      },
      "id": "IOYhUOdcEerG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsearle revised the speech acts classification and claimed that all speech acts fall into five categories: (1) representative/assertive: speech act that expresses speaker‚Äôs belief and that commits the speaker to the truth of what is asserted (i.e., words fit the world. example: üòÇ statements); (2) directive: speech act that expresses speaker‚Äôs wish and making an attempt to get the hearer to do something (i.e., world fits the words. example: requests); (3) commissive: speech act that expresses speaker‚Äôs intention and marking the commitment for the speaker to engage in future action (i.e., world fits the words. example: promise); (4) expressive: speech act that expresses speaker‚Äôs psychological states which has no direction of fit between the world and words (example: apologies) and (5) declaration: speech act that brings change in (institutional) reality and has bilateral fit between world and words (example: baptizing). üòÇ\\nüëç a number of studies have applied speech acts analysis in cmc environments. v√°squez (2011) studied complaints on the travel website tripadvisor and concluded that complaints co-occurred more frequently with advice and recommendations and they were considered mostly indirect in nature. other studies focused on users‚Äô self-representation in cmc environments. by examining away messages in instant messenger (im), nastri et al. (2006) found that they were constructed primarily with assertives, followed by expressives and commissives, but seldom with directives. the authors concluded that away messages tended to reflect both informational and entertainment goals. similarly, carr et al. (2012) investigated self-presentation in facebook status messages and found that they were mostly constructed with expressives, followed by assertives. üòç their findings demonstrated differences in how users expressed themselves in alternate media. given that text-based speech acts often co-occur with emoticons and emojis in cmc, some studies have investigated the relationship between speech acts and emoticon usage in message construction. dresner and herring (2010) examined the pragmatic function of emoticons and argued that the primary function of emoticon was not to convey emotion but to indicate an illocutionary force, which is the intended effect of the utterance. while their study provided a more nuanced understanding of the functions of emoticons, their study was not situated in a particular cmc setting. in light of this, skovholt et al. (2014) investigated the communicative functions of emoticons in workplace emails by adopting speech act theory and politeness theory. through identification of speech acts followed by emoticons in workplace emails, they found that emoticons contributed to modifying the propositional content and the illocutionary force of speech acts, which corresponded with drenser and herring‚Äôs results (2010). üòç more recently, the popularity of emoji use have attracted scholars‚Äô interests. ge-stadnyk (2021) examined and compared how social media influencers on weibo (a chinese microblogging site) and twitter used emoji sequences when engaging in self-presentation. the study identified a variety of text-based speech acts, emoji functions, and functional relations by conducting speech act and pragmatic function analyses and claimed that emoji sequences functioning as ‚Äòemphasis on text‚Äô was most employed in connection with accompanying texts in both weibo and twitter data (p. 378). to our best knowledge, studies on speech acts with emoji usage in self-help online discussion forums is sparse. this study expands the current research scope by examining the text-based speech acts and the communicative functions of emoji in an online self-help discussion forum related to covid-19, with the aim to investigate how hong kong forum users framed their covid-19 experiences, expressed their emotions and seek socioemotional support from others amid a global health crisis. üòç\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Tokenization**"
      ],
      "metadata": {
        "id": "tjJchv1LK5aZ"
      },
      "id": "tjJchv1LK5aZ"
    },
    {
      "cell_type": "code",
      "source": [
        "tokens =nltk.word_tokenize(normalized_text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWK-q7O5KxR4",
        "outputId": "1433fc6c-5cc9-4f80-b775-016a91ad345a"
      },
      "id": "wWK-q7O5KxR4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['searle',\n",
              " 'revised',\n",
              " 'the',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'classification',\n",
              " 'and',\n",
              " 'claimed',\n",
              " 'that',\n",
              " 'all',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'fall',\n",
              " 'into',\n",
              " 'five',\n",
              " 'categories',\n",
              " ':',\n",
              " '(',\n",
              " '1',\n",
              " ')',\n",
              " 'representative/assertive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'that',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 's',\n",
              " 'belief',\n",
              " 'and',\n",
              " 'that',\n",
              " 'commits',\n",
              " 'the',\n",
              " 'speaker',\n",
              " 'to',\n",
              " 'the',\n",
              " 'truth',\n",
              " 'of',\n",
              " 'what',\n",
              " 'is',\n",
              " 'asserted',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'words',\n",
              " 'fit',\n",
              " 'the',\n",
              " 'world',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'üòÇ',\n",
              " 'statements',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '2',\n",
              " ')',\n",
              " 'directive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'that',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 's',\n",
              " 'wish',\n",
              " 'and',\n",
              " 'making',\n",
              " 'an',\n",
              " 'attempt',\n",
              " 'to',\n",
              " 'get',\n",
              " 'the',\n",
              " 'hearer',\n",
              " 'to',\n",
              " 'do',\n",
              " 'something',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fits',\n",
              " 'the',\n",
              " 'words',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'requests',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '3',\n",
              " ')',\n",
              " 'commissive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'that',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 's',\n",
              " 'intention',\n",
              " 'and',\n",
              " 'marking',\n",
              " 'the',\n",
              " 'commitment',\n",
              " 'for',\n",
              " 'the',\n",
              " 'speaker',\n",
              " 'to',\n",
              " 'engage',\n",
              " 'in',\n",
              " 'future',\n",
              " 'action',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fits',\n",
              " 'the',\n",
              " 'words',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'promise',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '4',\n",
              " ')',\n",
              " 'expressive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'that',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 's',\n",
              " 'psychological',\n",
              " 'states',\n",
              " 'which',\n",
              " 'has',\n",
              " 'no',\n",
              " 'direction',\n",
              " 'of',\n",
              " 'fit',\n",
              " 'between',\n",
              " 'the',\n",
              " 'world',\n",
              " 'and',\n",
              " 'words',\n",
              " '(',\n",
              " 'example',\n",
              " ':',\n",
              " 'apologies',\n",
              " ')',\n",
              " 'and',\n",
              " '(',\n",
              " '5',\n",
              " ')',\n",
              " 'declaration',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'that',\n",
              " 'brings',\n",
              " 'change',\n",
              " 'in',\n",
              " '(',\n",
              " 'institutional',\n",
              " ')',\n",
              " 'reality',\n",
              " 'and',\n",
              " 'has',\n",
              " 'bilateral',\n",
              " 'fit',\n",
              " 'between',\n",
              " 'world',\n",
              " 'and',\n",
              " 'words',\n",
              " '(',\n",
              " 'example',\n",
              " ':',\n",
              " 'baptizing',\n",
              " ')',\n",
              " '.',\n",
              " 'üòÇ',\n",
              " 'üëç',\n",
              " 'a',\n",
              " 'number',\n",
              " 'of',\n",
              " 'studies',\n",
              " 'have',\n",
              " 'applied',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'analysis',\n",
              " 'in',\n",
              " 'cmc',\n",
              " 'environments',\n",
              " '.',\n",
              " 'v√°squez',\n",
              " '(',\n",
              " '2011',\n",
              " ')',\n",
              " 'studied',\n",
              " 'complaints',\n",
              " 'on',\n",
              " 'the',\n",
              " 'travel',\n",
              " 'website',\n",
              " 'tripadvisor',\n",
              " 'and',\n",
              " 'concluded',\n",
              " 'that',\n",
              " 'complaints',\n",
              " 'co-occurred',\n",
              " 'more',\n",
              " 'frequently',\n",
              " 'with',\n",
              " 'advice',\n",
              " 'and',\n",
              " 'recommendations',\n",
              " 'and',\n",
              " 'they',\n",
              " 'were',\n",
              " 'considered',\n",
              " 'mostly',\n",
              " 'indirect',\n",
              " 'in',\n",
              " 'nature',\n",
              " '.',\n",
              " 'other',\n",
              " 'studies',\n",
              " 'focused',\n",
              " 'on',\n",
              " 'users',\n",
              " '‚Äô',\n",
              " 'self-representation',\n",
              " 'in',\n",
              " 'cmc',\n",
              " 'environments',\n",
              " '.',\n",
              " 'by',\n",
              " 'examining',\n",
              " 'away',\n",
              " 'messages',\n",
              " 'in',\n",
              " 'instant',\n",
              " 'messenger',\n",
              " '(',\n",
              " 'im',\n",
              " ')',\n",
              " ',',\n",
              " 'nastri',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2006',\n",
              " ')',\n",
              " 'found',\n",
              " 'that',\n",
              " 'they',\n",
              " 'were',\n",
              " 'constructed',\n",
              " 'primarily',\n",
              " 'with',\n",
              " 'assertives',\n",
              " ',',\n",
              " 'followed',\n",
              " 'by',\n",
              " 'expressives',\n",
              " 'and',\n",
              " 'commissives',\n",
              " ',',\n",
              " 'but',\n",
              " 'seldom',\n",
              " 'with',\n",
              " 'directives',\n",
              " '.',\n",
              " 'the',\n",
              " 'authors',\n",
              " 'concluded',\n",
              " 'that',\n",
              " 'away',\n",
              " 'messages',\n",
              " 'tended',\n",
              " 'to',\n",
              " 'reflect',\n",
              " 'both',\n",
              " 'informational',\n",
              " 'and',\n",
              " 'entertainment',\n",
              " 'goals',\n",
              " '.',\n",
              " 'similarly',\n",
              " ',',\n",
              " 'carr',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2012',\n",
              " ')',\n",
              " 'investigated',\n",
              " 'self-presentation',\n",
              " 'in',\n",
              " 'facebook',\n",
              " 'status',\n",
              " 'messages',\n",
              " 'and',\n",
              " 'found',\n",
              " 'that',\n",
              " 'they',\n",
              " 'were',\n",
              " 'mostly',\n",
              " 'constructed',\n",
              " 'with',\n",
              " 'expressives',\n",
              " ',',\n",
              " 'followed',\n",
              " 'by',\n",
              " 'assertives',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'their',\n",
              " 'findings',\n",
              " 'demonstrated',\n",
              " 'differences',\n",
              " 'in',\n",
              " 'how',\n",
              " 'users',\n",
              " 'expressed',\n",
              " 'themselves',\n",
              " 'in',\n",
              " 'alternate',\n",
              " 'media',\n",
              " '.',\n",
              " 'given',\n",
              " 'that',\n",
              " 'text-based',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'often',\n",
              " 'co-occur',\n",
              " 'with',\n",
              " 'emoticons',\n",
              " 'and',\n",
              " 'emojis',\n",
              " 'in',\n",
              " 'cmc',\n",
              " ',',\n",
              " 'some',\n",
              " 'studies',\n",
              " 'have',\n",
              " 'investigated',\n",
              " 'the',\n",
              " 'relationship',\n",
              " 'between',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'and',\n",
              " 'emoticon',\n",
              " 'usage',\n",
              " 'in',\n",
              " 'message',\n",
              " 'construction',\n",
              " '.',\n",
              " 'dresner',\n",
              " 'and',\n",
              " 'herring',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " 'examined',\n",
              " 'the',\n",
              " 'pragmatic',\n",
              " 'function',\n",
              " 'of',\n",
              " 'emoticons',\n",
              " 'and',\n",
              " 'argued',\n",
              " 'that',\n",
              " 'the',\n",
              " 'primary',\n",
              " 'function',\n",
              " 'of',\n",
              " 'emoticon',\n",
              " 'was',\n",
              " 'not',\n",
              " 'to',\n",
              " 'convey',\n",
              " 'emotion',\n",
              " 'but',\n",
              " 'to',\n",
              " 'indicate',\n",
              " 'an',\n",
              " 'illocutionary',\n",
              " 'force',\n",
              " ',',\n",
              " 'which',\n",
              " 'is',\n",
              " 'the',\n",
              " 'intended',\n",
              " 'effect',\n",
              " 'of',\n",
              " 'the',\n",
              " 'utterance',\n",
              " '.',\n",
              " 'while',\n",
              " 'their',\n",
              " 'study',\n",
              " 'provided',\n",
              " 'a',\n",
              " 'more',\n",
              " 'nuanced',\n",
              " 'understanding',\n",
              " 'of',\n",
              " 'the',\n",
              " 'functions',\n",
              " 'of',\n",
              " 'emoticons',\n",
              " ',',\n",
              " 'their',\n",
              " 'study',\n",
              " 'was',\n",
              " 'not',\n",
              " 'situated',\n",
              " 'in',\n",
              " 'a',\n",
              " 'particular',\n",
              " 'cmc',\n",
              " 'setting',\n",
              " '.',\n",
              " 'in',\n",
              " 'light',\n",
              " 'of',\n",
              " 'this',\n",
              " ',',\n",
              " 'skovholt',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2014',\n",
              " ')',\n",
              " 'investigated',\n",
              " 'the',\n",
              " 'communicative',\n",
              " 'functions',\n",
              " 'of',\n",
              " 'emoticons',\n",
              " 'in',\n",
              " 'workplace',\n",
              " 'emails',\n",
              " 'by',\n",
              " 'adopting',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'theory',\n",
              " 'and',\n",
              " 'politeness',\n",
              " 'theory',\n",
              " '.',\n",
              " 'through',\n",
              " 'identification',\n",
              " 'of',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'followed',\n",
              " 'by',\n",
              " 'emoticons',\n",
              " 'in',\n",
              " 'workplace',\n",
              " 'emails',\n",
              " ',',\n",
              " 'they',\n",
              " 'found',\n",
              " 'that',\n",
              " 'emoticons',\n",
              " 'contributed',\n",
              " 'to',\n",
              " 'modifying',\n",
              " 'the',\n",
              " 'propositional',\n",
              " 'content',\n",
              " 'and',\n",
              " 'the',\n",
              " 'illocutionary',\n",
              " 'force',\n",
              " 'of',\n",
              " 'speech',\n",
              " 'acts',\n",
              " ',',\n",
              " 'which',\n",
              " 'corresponded',\n",
              " 'with',\n",
              " 'drenser',\n",
              " 'and',\n",
              " 'herring',\n",
              " '‚Äô',\n",
              " 's',\n",
              " 'results',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'more',\n",
              " 'recently',\n",
              " ',',\n",
              " 'the',\n",
              " 'popularity',\n",
              " 'of',\n",
              " 'emoji',\n",
              " 'use',\n",
              " 'have',\n",
              " 'attracted',\n",
              " 'scholars',\n",
              " '‚Äô',\n",
              " 'interests',\n",
              " '.',\n",
              " 'ge-stadnyk',\n",
              " '(',\n",
              " '2021',\n",
              " ')',\n",
              " 'examined',\n",
              " 'and',\n",
              " 'compared',\n",
              " 'how',\n",
              " 'social',\n",
              " 'media',\n",
              " 'influencers',\n",
              " 'on',\n",
              " 'weibo',\n",
              " '(',\n",
              " 'a',\n",
              " 'chinese',\n",
              " 'microblogging',\n",
              " 'site',\n",
              " ')',\n",
              " 'and',\n",
              " 'twitter',\n",
              " 'used',\n",
              " 'emoji',\n",
              " 'sequences',\n",
              " 'when',\n",
              " 'engaging',\n",
              " 'in',\n",
              " 'self-presentation',\n",
              " '.',\n",
              " 'the',\n",
              " 'study',\n",
              " 'identified',\n",
              " 'a',\n",
              " 'variety',\n",
              " 'of',\n",
              " 'text-based',\n",
              " 'speech',\n",
              " 'acts',\n",
              " ',',\n",
              " 'emoji',\n",
              " 'functions',\n",
              " ',',\n",
              " 'and',\n",
              " 'functional',\n",
              " 'relations',\n",
              " 'by',\n",
              " 'conducting',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'and',\n",
              " 'pragmatic',\n",
              " 'function',\n",
              " 'analyses',\n",
              " 'and',\n",
              " 'claimed',\n",
              " 'that',\n",
              " 'emoji',\n",
              " 'sequences',\n",
              " 'functioning',\n",
              " 'as',\n",
              " '‚Äò',\n",
              " 'emphasis',\n",
              " 'on',\n",
              " 'text',\n",
              " '‚Äô',\n",
              " 'was',\n",
              " 'most',\n",
              " 'employed',\n",
              " 'in',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'accompanying',\n",
              " 'texts',\n",
              " 'in',\n",
              " 'both',\n",
              " 'weibo',\n",
              " 'and',\n",
              " 'twitter',\n",
              " 'data',\n",
              " '(',\n",
              " 'p.',\n",
              " '378',\n",
              " ')',\n",
              " '.',\n",
              " 'to',\n",
              " 'our',\n",
              " 'best',\n",
              " 'knowledge',\n",
              " ',',\n",
              " 'studies',\n",
              " 'on',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'with',\n",
              " 'emoji',\n",
              " 'usage',\n",
              " 'in',\n",
              " 'self-help',\n",
              " 'online',\n",
              " 'discussion',\n",
              " 'forums',\n",
              " 'is',\n",
              " 'sparse',\n",
              " '.',\n",
              " 'this',\n",
              " 'study',\n",
              " 'expands',\n",
              " 'the',\n",
              " 'current',\n",
              " 'research',\n",
              " 'scope',\n",
              " 'by',\n",
              " 'examining',\n",
              " 'the',\n",
              " 'text-based',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'and',\n",
              " 'the',\n",
              " 'communicative',\n",
              " 'functions',\n",
              " 'of',\n",
              " 'emoji',\n",
              " 'in',\n",
              " 'an',\n",
              " 'online',\n",
              " 'self-help',\n",
              " 'discussion',\n",
              " 'forum',\n",
              " 'related',\n",
              " 'to',\n",
              " 'covid-19',\n",
              " ',',\n",
              " 'with',\n",
              " 'the',\n",
              " 'aim',\n",
              " 'to',\n",
              " 'investigate',\n",
              " 'how',\n",
              " 'hong',\n",
              " 'kong',\n",
              " 'forum',\n",
              " 'users',\n",
              " 'framed',\n",
              " 'their',\n",
              " 'covid-19',\n",
              " 'experiences',\n",
              " ',',\n",
              " 'expressed',\n",
              " 'their',\n",
              " 'emotions',\n",
              " 'and',\n",
              " 'seek',\n",
              " 'socioemotional',\n",
              " 'support',\n",
              " 'from',\n",
              " 'others',\n",
              " 'amid',\n",
              " 'a',\n",
              " 'global',\n",
              " 'health',\n",
              " 'crisis',\n",
              " '.',\n",
              " 'üòç']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Stop-word removal**"
      ],
      "metadata": {
        "id": "77SO4SoaLXUx"
      },
      "id": "77SO4SoaLXUx"
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [words for words in tokens if words not in stop_words]\n",
        "filtered_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVRYvLnTLUAS",
        "outputId": "159bc4f9-afc0-4060-f217-100b826e370b"
      },
      "id": "CVRYvLnTLUAS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['searle',\n",
              " 'revised',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'classification',\n",
              " 'claimed',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'fall',\n",
              " 'five',\n",
              " 'categories',\n",
              " ':',\n",
              " '(',\n",
              " '1',\n",
              " ')',\n",
              " 'representative/assertive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'belief',\n",
              " 'commits',\n",
              " 'speaker',\n",
              " 'truth',\n",
              " 'asserted',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'words',\n",
              " 'fit',\n",
              " 'world',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'üòÇ',\n",
              " 'statements',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '2',\n",
              " ')',\n",
              " 'directive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'wish',\n",
              " 'making',\n",
              " 'attempt',\n",
              " 'get',\n",
              " 'hearer',\n",
              " 'something',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fits',\n",
              " 'words',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'requests',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '3',\n",
              " ')',\n",
              " 'commissive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'intention',\n",
              " 'marking',\n",
              " 'commitment',\n",
              " 'speaker',\n",
              " 'engage',\n",
              " 'future',\n",
              " 'action',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fits',\n",
              " 'words',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'promise',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '4',\n",
              " ')',\n",
              " 'expressive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'expresses',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'psychological',\n",
              " 'states',\n",
              " 'direction',\n",
              " 'fit',\n",
              " 'world',\n",
              " 'words',\n",
              " '(',\n",
              " 'example',\n",
              " ':',\n",
              " 'apologies',\n",
              " ')',\n",
              " '(',\n",
              " '5',\n",
              " ')',\n",
              " 'declaration',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'brings',\n",
              " 'change',\n",
              " '(',\n",
              " 'institutional',\n",
              " ')',\n",
              " 'reality',\n",
              " 'bilateral',\n",
              " 'fit',\n",
              " 'world',\n",
              " 'words',\n",
              " '(',\n",
              " 'example',\n",
              " ':',\n",
              " 'baptizing',\n",
              " ')',\n",
              " '.',\n",
              " 'üòÇ',\n",
              " 'üëç',\n",
              " 'number',\n",
              " 'studies',\n",
              " 'applied',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'analysis',\n",
              " 'cmc',\n",
              " 'environments',\n",
              " '.',\n",
              " 'v√°squez',\n",
              " '(',\n",
              " '2011',\n",
              " ')',\n",
              " 'studied',\n",
              " 'complaints',\n",
              " 'travel',\n",
              " 'website',\n",
              " 'tripadvisor',\n",
              " 'concluded',\n",
              " 'complaints',\n",
              " 'co-occurred',\n",
              " 'frequently',\n",
              " 'advice',\n",
              " 'recommendations',\n",
              " 'considered',\n",
              " 'mostly',\n",
              " 'indirect',\n",
              " 'nature',\n",
              " '.',\n",
              " 'studies',\n",
              " 'focused',\n",
              " 'users',\n",
              " '‚Äô',\n",
              " 'self-representation',\n",
              " 'cmc',\n",
              " 'environments',\n",
              " '.',\n",
              " 'examining',\n",
              " 'away',\n",
              " 'messages',\n",
              " 'instant',\n",
              " 'messenger',\n",
              " '(',\n",
              " 'im',\n",
              " ')',\n",
              " ',',\n",
              " 'nastri',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2006',\n",
              " ')',\n",
              " 'found',\n",
              " 'constructed',\n",
              " 'primarily',\n",
              " 'assertives',\n",
              " ',',\n",
              " 'followed',\n",
              " 'expressives',\n",
              " 'commissives',\n",
              " ',',\n",
              " 'seldom',\n",
              " 'directives',\n",
              " '.',\n",
              " 'authors',\n",
              " 'concluded',\n",
              " 'away',\n",
              " 'messages',\n",
              " 'tended',\n",
              " 'reflect',\n",
              " 'informational',\n",
              " 'entertainment',\n",
              " 'goals',\n",
              " '.',\n",
              " 'similarly',\n",
              " ',',\n",
              " 'carr',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2012',\n",
              " ')',\n",
              " 'investigated',\n",
              " 'self-presentation',\n",
              " 'facebook',\n",
              " 'status',\n",
              " 'messages',\n",
              " 'found',\n",
              " 'mostly',\n",
              " 'constructed',\n",
              " 'expressives',\n",
              " ',',\n",
              " 'followed',\n",
              " 'assertives',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'findings',\n",
              " 'demonstrated',\n",
              " 'differences',\n",
              " 'users',\n",
              " 'expressed',\n",
              " 'alternate',\n",
              " 'media',\n",
              " '.',\n",
              " 'given',\n",
              " 'text-based',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'often',\n",
              " 'co-occur',\n",
              " 'emoticons',\n",
              " 'emojis',\n",
              " 'cmc',\n",
              " ',',\n",
              " 'studies',\n",
              " 'investigated',\n",
              " 'relationship',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'emoticon',\n",
              " 'usage',\n",
              " 'message',\n",
              " 'construction',\n",
              " '.',\n",
              " 'dresner',\n",
              " 'herring',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " 'examined',\n",
              " 'pragmatic',\n",
              " 'function',\n",
              " 'emoticons',\n",
              " 'argued',\n",
              " 'primary',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " 'convey',\n",
              " 'emotion',\n",
              " 'indicate',\n",
              " 'illocutionary',\n",
              " 'force',\n",
              " ',',\n",
              " 'intended',\n",
              " 'effect',\n",
              " 'utterance',\n",
              " '.',\n",
              " 'study',\n",
              " 'provided',\n",
              " 'nuanced',\n",
              " 'understanding',\n",
              " 'functions',\n",
              " 'emoticons',\n",
              " ',',\n",
              " 'study',\n",
              " 'situated',\n",
              " 'particular',\n",
              " 'cmc',\n",
              " 'setting',\n",
              " '.',\n",
              " 'light',\n",
              " ',',\n",
              " 'skovholt',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2014',\n",
              " ')',\n",
              " 'investigated',\n",
              " 'communicative',\n",
              " 'functions',\n",
              " 'emoticons',\n",
              " 'workplace',\n",
              " 'emails',\n",
              " 'adopting',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'theory',\n",
              " 'politeness',\n",
              " 'theory',\n",
              " '.',\n",
              " 'identification',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'followed',\n",
              " 'emoticons',\n",
              " 'workplace',\n",
              " 'emails',\n",
              " ',',\n",
              " 'found',\n",
              " 'emoticons',\n",
              " 'contributed',\n",
              " 'modifying',\n",
              " 'propositional',\n",
              " 'content',\n",
              " 'illocutionary',\n",
              " 'force',\n",
              " 'speech',\n",
              " 'acts',\n",
              " ',',\n",
              " 'corresponded',\n",
              " 'drenser',\n",
              " 'herring',\n",
              " '‚Äô',\n",
              " 'results',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'recently',\n",
              " ',',\n",
              " 'popularity',\n",
              " 'emoji',\n",
              " 'use',\n",
              " 'attracted',\n",
              " 'scholars',\n",
              " '‚Äô',\n",
              " 'interests',\n",
              " '.',\n",
              " 'ge-stadnyk',\n",
              " '(',\n",
              " '2021',\n",
              " ')',\n",
              " 'examined',\n",
              " 'compared',\n",
              " 'social',\n",
              " 'media',\n",
              " 'influencers',\n",
              " 'weibo',\n",
              " '(',\n",
              " 'chinese',\n",
              " 'microblogging',\n",
              " 'site',\n",
              " ')',\n",
              " 'twitter',\n",
              " 'used',\n",
              " 'emoji',\n",
              " 'sequences',\n",
              " 'engaging',\n",
              " 'self-presentation',\n",
              " '.',\n",
              " 'study',\n",
              " 'identified',\n",
              " 'variety',\n",
              " 'text-based',\n",
              " 'speech',\n",
              " 'acts',\n",
              " ',',\n",
              " 'emoji',\n",
              " 'functions',\n",
              " ',',\n",
              " 'functional',\n",
              " 'relations',\n",
              " 'conducting',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'pragmatic',\n",
              " 'function',\n",
              " 'analyses',\n",
              " 'claimed',\n",
              " 'emoji',\n",
              " 'sequences',\n",
              " 'functioning',\n",
              " '‚Äò',\n",
              " 'emphasis',\n",
              " 'text',\n",
              " '‚Äô',\n",
              " 'employed',\n",
              " 'connection',\n",
              " 'accompanying',\n",
              " 'texts',\n",
              " 'weibo',\n",
              " 'twitter',\n",
              " 'data',\n",
              " '(',\n",
              " 'p.',\n",
              " '378',\n",
              " ')',\n",
              " '.',\n",
              " 'best',\n",
              " 'knowledge',\n",
              " ',',\n",
              " 'studies',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'emoji',\n",
              " 'usage',\n",
              " 'self-help',\n",
              " 'online',\n",
              " 'discussion',\n",
              " 'forums',\n",
              " 'sparse',\n",
              " '.',\n",
              " 'study',\n",
              " 'expands',\n",
              " 'current',\n",
              " 'research',\n",
              " 'scope',\n",
              " 'examining',\n",
              " 'text-based',\n",
              " 'speech',\n",
              " 'acts',\n",
              " 'communicative',\n",
              " 'functions',\n",
              " 'emoji',\n",
              " 'online',\n",
              " 'self-help',\n",
              " 'discussion',\n",
              " 'forum',\n",
              " 'related',\n",
              " 'covid-19',\n",
              " ',',\n",
              " 'aim',\n",
              " 'investigate',\n",
              " 'hong',\n",
              " 'kong',\n",
              " 'forum',\n",
              " 'users',\n",
              " 'framed',\n",
              " 'covid-19',\n",
              " 'experiences',\n",
              " ',',\n",
              " 'expressed',\n",
              " 'emotions',\n",
              " 'seek',\n",
              " 'socioemotional',\n",
              " 'support',\n",
              " 'others',\n",
              " 'amid',\n",
              " 'global',\n",
              " 'health',\n",
              " 'crisis',\n",
              " '.',\n",
              " 'üòç']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Stemming**"
      ],
      "metadata": {
        "id": "jNq0PURNMQyk"
      },
      "id": "jNq0PURNMQyk"
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens ]\n",
        "stemmed_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuSDkRiXMBaJ",
        "outputId": "5bf04168-aa0b-45a1-c707-1f54c2f56342"
      },
      "id": "SuSDkRiXMBaJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['searl',\n",
              " 'revis',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'classif',\n",
              " 'claim',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'fall',\n",
              " 'five',\n",
              " 'categori',\n",
              " ':',\n",
              " '(',\n",
              " '1',\n",
              " ')',\n",
              " 'representative/assert',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'belief',\n",
              " 'commit',\n",
              " 'speaker',\n",
              " 'truth',\n",
              " 'assert',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'word',\n",
              " 'fit',\n",
              " 'world',\n",
              " '.',\n",
              " 'exampl',\n",
              " ':',\n",
              " 'üòÇ',\n",
              " 'statement',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '2',\n",
              " ')',\n",
              " 'direct',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'wish',\n",
              " 'make',\n",
              " 'attempt',\n",
              " 'get',\n",
              " 'hearer',\n",
              " 'someth',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fit',\n",
              " 'word',\n",
              " '.',\n",
              " 'exampl',\n",
              " ':',\n",
              " 'request',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '3',\n",
              " ')',\n",
              " 'commiss',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'intent',\n",
              " 'mark',\n",
              " 'commit',\n",
              " 'speaker',\n",
              " 'engag',\n",
              " 'futur',\n",
              " 'action',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fit',\n",
              " 'word',\n",
              " '.',\n",
              " 'exampl',\n",
              " ':',\n",
              " 'promis',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '4',\n",
              " ')',\n",
              " 'express',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " '‚Äô',\n",
              " 'psycholog',\n",
              " 'state',\n",
              " 'direct',\n",
              " 'fit',\n",
              " 'world',\n",
              " 'word',\n",
              " '(',\n",
              " 'exampl',\n",
              " ':',\n",
              " 'apolog',\n",
              " ')',\n",
              " '(',\n",
              " '5',\n",
              " ')',\n",
              " 'declar',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'bring',\n",
              " 'chang',\n",
              " '(',\n",
              " 'institut',\n",
              " ')',\n",
              " 'realiti',\n",
              " 'bilater',\n",
              " 'fit',\n",
              " 'world',\n",
              " 'word',\n",
              " '(',\n",
              " 'exampl',\n",
              " ':',\n",
              " 'baptiz',\n",
              " ')',\n",
              " '.',\n",
              " 'üòÇ',\n",
              " 'üëç',\n",
              " 'number',\n",
              " 'studi',\n",
              " 'appli',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'analysi',\n",
              " 'cmc',\n",
              " 'environ',\n",
              " '.',\n",
              " 'v√°squez',\n",
              " '(',\n",
              " '2011',\n",
              " ')',\n",
              " 'studi',\n",
              " 'complaint',\n",
              " 'travel',\n",
              " 'websit',\n",
              " 'tripadvisor',\n",
              " 'conclud',\n",
              " 'complaint',\n",
              " 'co-occur',\n",
              " 'frequent',\n",
              " 'advic',\n",
              " 'recommend',\n",
              " 'consid',\n",
              " 'mostli',\n",
              " 'indirect',\n",
              " 'natur',\n",
              " '.',\n",
              " 'studi',\n",
              " 'focus',\n",
              " 'user',\n",
              " '‚Äô',\n",
              " 'self-represent',\n",
              " 'cmc',\n",
              " 'environ',\n",
              " '.',\n",
              " 'examin',\n",
              " 'away',\n",
              " 'messag',\n",
              " 'instant',\n",
              " 'messeng',\n",
              " '(',\n",
              " 'im',\n",
              " ')',\n",
              " ',',\n",
              " 'nastri',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2006',\n",
              " ')',\n",
              " 'found',\n",
              " 'construct',\n",
              " 'primarili',\n",
              " 'assert',\n",
              " ',',\n",
              " 'follow',\n",
              " 'express',\n",
              " 'commiss',\n",
              " ',',\n",
              " 'seldom',\n",
              " 'direct',\n",
              " '.',\n",
              " 'author',\n",
              " 'conclud',\n",
              " 'away',\n",
              " 'messag',\n",
              " 'tend',\n",
              " 'reflect',\n",
              " 'inform',\n",
              " 'entertain',\n",
              " 'goal',\n",
              " '.',\n",
              " 'similarli',\n",
              " ',',\n",
              " 'carr',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2012',\n",
              " ')',\n",
              " 'investig',\n",
              " 'self-present',\n",
              " 'facebook',\n",
              " 'statu',\n",
              " 'messag',\n",
              " 'found',\n",
              " 'mostli',\n",
              " 'construct',\n",
              " 'express',\n",
              " ',',\n",
              " 'follow',\n",
              " 'assert',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'find',\n",
              " 'demonstr',\n",
              " 'differ',\n",
              " 'user',\n",
              " 'express',\n",
              " 'altern',\n",
              " 'media',\n",
              " '.',\n",
              " 'given',\n",
              " 'text-bas',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'often',\n",
              " 'co-occur',\n",
              " 'emoticon',\n",
              " 'emoji',\n",
              " 'cmc',\n",
              " ',',\n",
              " 'studi',\n",
              " 'investig',\n",
              " 'relationship',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'emoticon',\n",
              " 'usag',\n",
              " 'messag',\n",
              " 'construct',\n",
              " '.',\n",
              " 'dresner',\n",
              " 'her',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " 'examin',\n",
              " 'pragmat',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " 'argu',\n",
              " 'primari',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " 'convey',\n",
              " 'emot',\n",
              " 'indic',\n",
              " 'illocutionari',\n",
              " 'forc',\n",
              " ',',\n",
              " 'intend',\n",
              " 'effect',\n",
              " 'utter',\n",
              " '.',\n",
              " 'studi',\n",
              " 'provid',\n",
              " 'nuanc',\n",
              " 'understand',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " ',',\n",
              " 'studi',\n",
              " 'situat',\n",
              " 'particular',\n",
              " 'cmc',\n",
              " 'set',\n",
              " '.',\n",
              " 'light',\n",
              " ',',\n",
              " 'skovholt',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2014',\n",
              " ')',\n",
              " 'investig',\n",
              " 'commun',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " 'workplac',\n",
              " 'email',\n",
              " 'adopt',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'theori',\n",
              " 'polit',\n",
              " 'theori',\n",
              " '.',\n",
              " 'identif',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'follow',\n",
              " 'emoticon',\n",
              " 'workplac',\n",
              " 'email',\n",
              " ',',\n",
              " 'found',\n",
              " 'emoticon',\n",
              " 'contribut',\n",
              " 'modifi',\n",
              " 'proposit',\n",
              " 'content',\n",
              " 'illocutionari',\n",
              " 'forc',\n",
              " 'speech',\n",
              " 'act',\n",
              " ',',\n",
              " 'correspond',\n",
              " 'drenser',\n",
              " 'her',\n",
              " '‚Äô',\n",
              " 'result',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'recent',\n",
              " ',',\n",
              " 'popular',\n",
              " 'emoji',\n",
              " 'use',\n",
              " 'attract',\n",
              " 'scholar',\n",
              " '‚Äô',\n",
              " 'interest',\n",
              " '.',\n",
              " 'ge-stadnyk',\n",
              " '(',\n",
              " '2021',\n",
              " ')',\n",
              " 'examin',\n",
              " 'compar',\n",
              " 'social',\n",
              " 'media',\n",
              " 'influenc',\n",
              " 'weibo',\n",
              " '(',\n",
              " 'chines',\n",
              " 'microblog',\n",
              " 'site',\n",
              " ')',\n",
              " 'twitter',\n",
              " 'use',\n",
              " 'emoji',\n",
              " 'sequenc',\n",
              " 'engag',\n",
              " 'self-present',\n",
              " '.',\n",
              " 'studi',\n",
              " 'identifi',\n",
              " 'varieti',\n",
              " 'text-bas',\n",
              " 'speech',\n",
              " 'act',\n",
              " ',',\n",
              " 'emoji',\n",
              " 'function',\n",
              " ',',\n",
              " 'function',\n",
              " 'relat',\n",
              " 'conduct',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'pragmat',\n",
              " 'function',\n",
              " 'analys',\n",
              " 'claim',\n",
              " 'emoji',\n",
              " 'sequenc',\n",
              " 'function',\n",
              " '‚Äò',\n",
              " 'emphasi',\n",
              " 'text',\n",
              " '‚Äô',\n",
              " 'employ',\n",
              " 'connect',\n",
              " 'accompani',\n",
              " 'text',\n",
              " 'weibo',\n",
              " 'twitter',\n",
              " 'data',\n",
              " '(',\n",
              " 'p.',\n",
              " '378',\n",
              " ')',\n",
              " '.',\n",
              " 'best',\n",
              " 'knowledg',\n",
              " ',',\n",
              " 'studi',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'emoji',\n",
              " 'usag',\n",
              " 'self-help',\n",
              " 'onlin',\n",
              " 'discuss',\n",
              " 'forum',\n",
              " 'spars',\n",
              " '.',\n",
              " 'studi',\n",
              " 'expand',\n",
              " 'current',\n",
              " 'research',\n",
              " 'scope',\n",
              " 'examin',\n",
              " 'text-bas',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'commun',\n",
              " 'function',\n",
              " 'emoji',\n",
              " 'onlin',\n",
              " 'self-help',\n",
              " 'discuss',\n",
              " 'forum',\n",
              " 'relat',\n",
              " 'covid-19',\n",
              " ',',\n",
              " 'aim',\n",
              " 'investig',\n",
              " 'hong',\n",
              " 'kong',\n",
              " 'forum',\n",
              " 'user',\n",
              " 'frame',\n",
              " 'covid-19',\n",
              " 'experi',\n",
              " ',',\n",
              " 'express',\n",
              " 'emot',\n",
              " 'seek',\n",
              " 'socioemot',\n",
              " 'support',\n",
              " 'other',\n",
              " 'amid',\n",
              " 'global',\n",
              " 'health',\n",
              " 'crisi',\n",
              " '.',\n",
              " 'üòç']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Lemmatization**"
      ],
      "metadata": {
        "id": "pSmaIEZWOic0"
      },
      "id": "pSmaIEZWOic0"
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(' '.join(filtered_tokens))\n",
        "lemmatized_tokens = [token.lemma_ for token in doc]\n",
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz3eAlQvNIIH",
        "outputId": "1a4ad285-397a-4b53-8d2d-8ce9cb967e3c"
      },
      "id": "qz3eAlQvNIIH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['searle',\n",
              " 'revise',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'classification',\n",
              " 'claim',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'fall',\n",
              " 'five',\n",
              " 'category',\n",
              " ':',\n",
              " '(',\n",
              " '1',\n",
              " ')',\n",
              " 'representative',\n",
              " '/',\n",
              " 'assertive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " \"'\",\n",
              " 'belief',\n",
              " 'commit',\n",
              " 'speaker',\n",
              " 'truth',\n",
              " 'assert',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'word',\n",
              " 'fit',\n",
              " 'world',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'üòÇ',\n",
              " 'statement',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '2',\n",
              " ')',\n",
              " 'directive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " \"'\",\n",
              " 'wish',\n",
              " 'make',\n",
              " 'attempt',\n",
              " 'get',\n",
              " 'hearer',\n",
              " 'something',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fit',\n",
              " 'word',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'request',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '3',\n",
              " ')',\n",
              " 'commissive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " \"'\",\n",
              " 'intention',\n",
              " 'mark',\n",
              " 'commitment',\n",
              " 'speaker',\n",
              " 'engage',\n",
              " 'future',\n",
              " 'action',\n",
              " '(',\n",
              " 'i.e.',\n",
              " ',',\n",
              " 'world',\n",
              " 'fit',\n",
              " 'word',\n",
              " '.',\n",
              " 'example',\n",
              " ':',\n",
              " 'promise',\n",
              " ')',\n",
              " ';',\n",
              " '(',\n",
              " '4',\n",
              " ')',\n",
              " 'expressive',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'express',\n",
              " 'speaker',\n",
              " \"'\",\n",
              " 'psychological',\n",
              " 'state',\n",
              " 'direction',\n",
              " 'fit',\n",
              " 'world',\n",
              " 'word',\n",
              " '(',\n",
              " 'example',\n",
              " ':',\n",
              " 'apology',\n",
              " ')',\n",
              " '(',\n",
              " '5',\n",
              " ')',\n",
              " 'declaration',\n",
              " ':',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'bring',\n",
              " 'change',\n",
              " '(',\n",
              " 'institutional',\n",
              " ')',\n",
              " 'reality',\n",
              " 'bilateral',\n",
              " 'fit',\n",
              " 'world',\n",
              " 'word',\n",
              " '(',\n",
              " 'example',\n",
              " ':',\n",
              " 'baptize',\n",
              " ')',\n",
              " '.',\n",
              " 'üòÇ',\n",
              " 'üëç',\n",
              " 'number',\n",
              " 'study',\n",
              " 'apply',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'analysis',\n",
              " 'cmc',\n",
              " 'environment',\n",
              " '.',\n",
              " 'v√°squez',\n",
              " '(',\n",
              " '2011',\n",
              " ')',\n",
              " 'study',\n",
              " 'complaint',\n",
              " 'travel',\n",
              " 'website',\n",
              " 'tripadvisor',\n",
              " 'conclude',\n",
              " 'complaint',\n",
              " 'co',\n",
              " '-',\n",
              " 'occur',\n",
              " 'frequently',\n",
              " 'advice',\n",
              " 'recommendation',\n",
              " 'consider',\n",
              " 'mostly',\n",
              " 'indirect',\n",
              " 'nature',\n",
              " '.',\n",
              " 'study',\n",
              " 'focus',\n",
              " 'user',\n",
              " '‚Äô',\n",
              " 'self',\n",
              " '-',\n",
              " 'representation',\n",
              " 'cmc',\n",
              " 'environment',\n",
              " '.',\n",
              " 'examine',\n",
              " 'away',\n",
              " 'message',\n",
              " 'instant',\n",
              " 'messenger',\n",
              " '(',\n",
              " 'i',\n",
              " 'm',\n",
              " ')',\n",
              " ',',\n",
              " 'nastri',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2006',\n",
              " ')',\n",
              " 'find',\n",
              " 'construct',\n",
              " 'primarily',\n",
              " 'assertive',\n",
              " ',',\n",
              " 'follow',\n",
              " 'expressive',\n",
              " 'commissive',\n",
              " ',',\n",
              " 'seldom',\n",
              " 'directive',\n",
              " '.',\n",
              " 'author',\n",
              " 'conclude',\n",
              " 'away',\n",
              " 'message',\n",
              " 'tend',\n",
              " 'reflect',\n",
              " 'informational',\n",
              " 'entertainment',\n",
              " 'goal',\n",
              " '.',\n",
              " 'similarly',\n",
              " ',',\n",
              " 'carr',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2012',\n",
              " ')',\n",
              " 'investigate',\n",
              " 'self',\n",
              " '-',\n",
              " 'presentation',\n",
              " 'facebook',\n",
              " 'status',\n",
              " 'message',\n",
              " 'find',\n",
              " 'mostly',\n",
              " 'construct',\n",
              " 'expressive',\n",
              " ',',\n",
              " 'follow',\n",
              " 'assertive',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'finding',\n",
              " 'demonstrate',\n",
              " 'difference',\n",
              " 'user',\n",
              " 'express',\n",
              " 'alternate',\n",
              " 'medium',\n",
              " '.',\n",
              " 'give',\n",
              " 'text',\n",
              " '-',\n",
              " 'base',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'often',\n",
              " 'co',\n",
              " '-',\n",
              " 'occur',\n",
              " 'emoticon',\n",
              " 'emojis',\n",
              " 'cmc',\n",
              " ',',\n",
              " 'study',\n",
              " 'investigate',\n",
              " 'relationship',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'emoticon',\n",
              " 'usage',\n",
              " 'message',\n",
              " 'construction',\n",
              " '.',\n",
              " 'dresner',\n",
              " 'herring',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " 'examine',\n",
              " 'pragmatic',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " 'argue',\n",
              " 'primary',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " 'convey',\n",
              " 'emotion',\n",
              " 'indicate',\n",
              " 'illocutionary',\n",
              " 'force',\n",
              " ',',\n",
              " 'intend',\n",
              " 'effect',\n",
              " 'utterance',\n",
              " '.',\n",
              " 'study',\n",
              " 'provide',\n",
              " 'nuance',\n",
              " 'understanding',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " ',',\n",
              " 'study',\n",
              " 'situate',\n",
              " 'particular',\n",
              " 'cmc',\n",
              " 'setting',\n",
              " '.',\n",
              " 'light',\n",
              " ',',\n",
              " 'skovholt',\n",
              " 'et',\n",
              " 'al',\n",
              " '.',\n",
              " '(',\n",
              " '2014',\n",
              " ')',\n",
              " 'investigate',\n",
              " 'communicative',\n",
              " 'function',\n",
              " 'emoticon',\n",
              " 'workplace',\n",
              " 'email',\n",
              " 'adopt',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'theory',\n",
              " 'politeness',\n",
              " 'theory',\n",
              " '.',\n",
              " 'identification',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'follow',\n",
              " 'emoticon',\n",
              " 'workplace',\n",
              " 'email',\n",
              " ',',\n",
              " 'find',\n",
              " 'emoticon',\n",
              " 'contribute',\n",
              " 'modify',\n",
              " 'propositional',\n",
              " 'content',\n",
              " 'illocutionary',\n",
              " 'force',\n",
              " 'speech',\n",
              " 'act',\n",
              " ',',\n",
              " 'correspond',\n",
              " 'drenser',\n",
              " 'herre',\n",
              " \"'\",\n",
              " 'result',\n",
              " '(',\n",
              " '2010',\n",
              " ')',\n",
              " '.',\n",
              " 'üòç',\n",
              " 'recently',\n",
              " ',',\n",
              " 'popularity',\n",
              " 'emoji',\n",
              " 'use',\n",
              " 'attract',\n",
              " 'scholar',\n",
              " '‚Äô',\n",
              " 'interest',\n",
              " '.',\n",
              " 'ge',\n",
              " '-',\n",
              " 'stadnyk',\n",
              " '(',\n",
              " '2021',\n",
              " ')',\n",
              " 'examine',\n",
              " 'compare',\n",
              " 'social',\n",
              " 'medium',\n",
              " 'influencer',\n",
              " 'weibo',\n",
              " '(',\n",
              " 'chinese',\n",
              " 'microblogging',\n",
              " 'site',\n",
              " ')',\n",
              " 'twitter',\n",
              " 'use',\n",
              " 'emoji',\n",
              " 'sequence',\n",
              " 'engage',\n",
              " 'self',\n",
              " '-',\n",
              " 'presentation',\n",
              " '.',\n",
              " 'study',\n",
              " 'identify',\n",
              " 'variety',\n",
              " 'text',\n",
              " '-',\n",
              " 'base',\n",
              " 'speech',\n",
              " 'act',\n",
              " ',',\n",
              " 'emoji',\n",
              " 'function',\n",
              " ',',\n",
              " 'functional',\n",
              " 'relation',\n",
              " 'conduct',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'pragmatic',\n",
              " 'function',\n",
              " 'analysis',\n",
              " 'claim',\n",
              " 'emoji',\n",
              " 'sequence',\n",
              " 'function',\n",
              " \"'\",\n",
              " 'emphasis',\n",
              " 'text',\n",
              " \"'\",\n",
              " 'employ',\n",
              " 'connection',\n",
              " 'accompany',\n",
              " 'text',\n",
              " 'weibo',\n",
              " 'twitter',\n",
              " 'datum',\n",
              " '(',\n",
              " 'p.',\n",
              " '378',\n",
              " ')',\n",
              " '.',\n",
              " 'good',\n",
              " 'knowledge',\n",
              " ',',\n",
              " 'study',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'emoji',\n",
              " 'usage',\n",
              " 'self',\n",
              " '-',\n",
              " 'help',\n",
              " 'online',\n",
              " 'discussion',\n",
              " 'forum',\n",
              " 'sparse',\n",
              " '.',\n",
              " 'study',\n",
              " 'expand',\n",
              " 'current',\n",
              " 'research',\n",
              " 'scope',\n",
              " 'examine',\n",
              " 'text',\n",
              " '-',\n",
              " 'base',\n",
              " 'speech',\n",
              " 'act',\n",
              " 'communicative',\n",
              " 'function',\n",
              " 'emoji',\n",
              " 'online',\n",
              " 'self',\n",
              " '-',\n",
              " 'help',\n",
              " 'discussion',\n",
              " 'forum',\n",
              " 'relate',\n",
              " 'covid-19',\n",
              " ',',\n",
              " 'aim',\n",
              " 'investigate',\n",
              " 'hong',\n",
              " 'kong',\n",
              " 'forum',\n",
              " 'user',\n",
              " 'frame',\n",
              " 'covid-19',\n",
              " 'experience',\n",
              " ',',\n",
              " 'express',\n",
              " 'emotion',\n",
              " 'seek',\n",
              " 'socioemotional',\n",
              " 'support',\n",
              " 'other',\n",
              " 'amid',\n",
              " 'global',\n",
              " 'health',\n",
              " 'crisis',\n",
              " '.',\n",
              " 'üòç']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Text Encoding**"
      ],
      "metadata": {
        "id": "PXeL9jYOQLVk"
      },
      "id": "PXeL9jYOQLVk"
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(lemmatized_tokens)\n",
        "encoded_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGigpasoPbdw",
        "outputId": "f1f580e9-1e61-4b2a-c319-c11f7014d62e"
      },
      "id": "EGigpasoPbdw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([188, 185, 203,  22,  50,  49, 203,  22, 100, 104,  46,  19,   1,\n",
              "         7,   2, 181,   6,  35,  19, 203,  22,  97, 202,   0,  42,  54,\n",
              "       202, 215,  34,   1, 127,   3, 227, 103, 229,   5,  94,  19, 232,\n",
              "       206,   2,  20,   1,   8,   2,  77,  19, 203,  22,  97, 202,   0,\n",
              "       226, 145,  36, 115, 121, 200,   1, 127,   3, 229, 103, 227,   5,\n",
              "        94,  19, 182,   2,  20,   1,  15,   2,  53,  19, 203,  22,  97,\n",
              "       202,   0, 138, 146,  55, 202,  89, 113,  23,   1, 127,   3, 229,\n",
              "       103, 227,   5,  94,  19, 169,   2,  20,   1,  17,   2,  98,  19,\n",
              "       203,  22,  97, 202,   0, 172, 205,  76, 103, 229, 227,   1,  94,\n",
              "        19,  31,   2,   1,  18,   2,  73,  19, 203,  22,  44,  47,   1,\n",
              "       136,   2, 173,  43, 103, 229, 227,   1,  94,  19,  40,   2,   5,\n",
              "       232, 231, 156, 208,  32, 203,  22,  30,  51,  91,   5, 223,   1,\n",
              "        11,   2, 208,  58, 213, 224, 214,  59,  58,  52,   4, 157, 110,\n",
              "        25, 175,  62, 152, 132, 154,   5, 208, 105, 220, 230, 191,   4,\n",
              "       180,  51,  91,   5,  93,  39, 148, 135, 149,   1, 126, 144,   2,\n",
              "         3, 153,  92,  27,   5,   1,   9,   2, 101,  63, 167,  35,   3,\n",
              "       106,  98,  53,   3, 190,  77,   5,  38,  59,  39, 148, 210, 176,\n",
              "       134,  90, 118,   5, 194,   3,  45,  92,  27,   5,   1,  12,   2,\n",
              "       140, 191,   4, 166,  99, 207, 148, 101, 152,  63,  98,   3, 106,\n",
              "        35,   5, 233, 102,  74,  75, 220,  97,  28, 147,   5, 116, 211,\n",
              "         4,  41, 203,  22, 158,  52,   4, 157,  85,  84,  51,   3, 208,\n",
              "       140, 179, 203,  22,  85, 218, 148,  64,   5,  80, 124,   1,  10,\n",
              "         2,  93, 165, 111,  85,  33, 168, 111,  85,  67,  86, 131, 130,\n",
              "       107,   3, 137,  81, 221,   5, 208, 171, 155, 217, 111,  85,   3,\n",
              "       208, 196, 162,  51, 193,   5, 143,   3, 197,  92,  27,   5,   1,\n",
              "        13,   2, 140,  56, 111,  85, 228,  82,  24, 203,  22, 212, 163,\n",
              "       212,   5, 128, 203,  22, 106,  85, 228,  82,   3, 101,  85,  66,\n",
              "       151, 170,  65, 130, 107, 203,  22,   3,  68,  79, 123,   0, 184,\n",
              "         1,  10,   2,   5, 233, 174,   3, 164,  83, 219,  37, 186, 230,\n",
              "       139,   5, 114,   4, 204,   1,  14,   2,  93,  57, 198, 147, 133,\n",
              "       225,   1,  48, 150, 195,   2, 216, 219,  83, 192,  89, 191,   4,\n",
              "       166,   5, 208, 129, 222, 211,   4,  41, 203,  22,   3,  83, 111,\n",
              "         3, 112, 178,  60, 203,  22, 165, 111,  30,  49,  83, 192, 111,\n",
              "         0,  87, 211,   0,  88,  61,  21, 211, 225, 216,  72,   1, 161,\n",
              "        16,   2,   5, 119, 141,   3, 208, 203,  22,  83, 218, 191,   4,\n",
              "       122, 159,  78, 108, 201,   5, 208,  95,  71, 183, 187,  93, 211,\n",
              "         4,  41, 203,  22,  56, 111,  83, 159, 191,   4, 122,  78, 108,\n",
              "       177,  69,   3,  26, 140, 125, 142, 108, 220, 109,  69,  96,   3,\n",
              "        97,  86, 189, 199, 209, 160,  29, 117, 120,  70,   5, 233])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Vectorization and Embeddings**"
      ],
      "metadata": {
        "id": "IGU6i6kXRDG9"
      },
      "id": "IGU6i6kXRDG9"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([' '.join(lemmatized_tokens)])\n",
        "vectors.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPZaXU-RSHsG",
        "outputId": "ff378288-9c3c-47e9-8be1-d7c90aa77153"
      },
      "id": "KPZaXU-RSHsG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05202269, 0.02601134, 0.05202269, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.44219284,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.07803403,\n",
              "        0.02601134, 0.02601134, 0.05202269, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.07803403, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.05202269, 0.02601134, 0.07803403, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.05202269, 0.02601134, 0.10404537, 0.05202269,\n",
              "        0.05202269, 0.02601134, 0.02601134, 0.05202269, 0.02601134,\n",
              "        0.05202269, 0.05202269, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.05202269, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.05202269, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.05202269,\n",
              "        0.05202269, 0.02601134, 0.02601134, 0.02601134, 0.05202269,\n",
              "        0.15606806, 0.02601134, 0.20809075, 0.05202269, 0.02601134,\n",
              "        0.02601134, 0.05202269, 0.02601134, 0.05202269, 0.07803403,\n",
              "        0.10404537, 0.13005672, 0.02601134, 0.02601134, 0.15606806,\n",
              "        0.07803403, 0.02601134, 0.02601134, 0.07803403, 0.02601134,\n",
              "        0.13005672, 0.02601134, 0.02601134, 0.07803403, 0.05202269,\n",
              "        0.07803403, 0.02601134, 0.02601134, 0.20809075, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.05202269,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.05202269, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.10404537, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.05202269, 0.10404537, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.05202269, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.05202269, 0.02601134, 0.05202269, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.05202269, 0.05202269,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.13005672,\n",
              "        0.05202269, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.15606806, 0.44219284, 0.02601134, 0.02601134, 0.02601134,\n",
              "        0.02601134, 0.23410209, 0.02601134, 0.02601134, 0.13005672,\n",
              "        0.05202269, 0.02601134, 0.02601134, 0.02601134, 0.05202269,\n",
              "        0.02601134, 0.05202269, 0.05202269, 0.07803403, 0.02601134,\n",
              "        0.02601134, 0.02601134, 0.02601134, 0.05202269, 0.02601134,\n",
              "        0.13005672, 0.05202269, 0.13005672]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Padding/Truncation**"
      ],
      "metadata": {
        "id": "hGkpJ1_nSVrO"
      },
      "id": "hGkpJ1_nSVrO"
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = [encoded_labels]\n",
        "padded_sequences = pad_sequences(sequences, maxlen = 100, padding = 'post', truncating = 'post')\n",
        "padded_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd0aimgzRqK-",
        "outputId": "8ffe2d65-acd8-4a55-8b5a-c25a694c6e78"
      },
      "id": "Cd0aimgzRqK-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[188, 185, 203,  22,  50,  49, 203,  22, 100, 104,  46,  19,   1,\n",
              "          7,   2, 181,   6,  35,  19, 203,  22,  97, 202,   0,  42,  54,\n",
              "        202, 215,  34,   1, 127,   3, 227, 103, 229,   5,  94,  19, 232,\n",
              "        206,   2,  20,   1,   8,   2,  77,  19, 203,  22,  97, 202,   0,\n",
              "        226, 145,  36, 115, 121, 200,   1, 127,   3, 229, 103, 227,   5,\n",
              "         94,  19, 182,   2,  20,   1,  15,   2,  53,  19, 203,  22,  97,\n",
              "        202,   0, 138, 146,  55, 202,  89, 113,  23,   1, 127,   3, 229,\n",
              "        103, 227,   5,  94,  19, 169,   2,  20,   1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWYzF6fzTYk9"
      },
      "id": "fWYzF6fzTYk9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}